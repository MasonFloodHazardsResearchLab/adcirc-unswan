{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and coverting ERA5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on the fifth generation ECMWF atmospheric reanalysis of the global climate ERA5 is found at:\n",
    "https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Requesting ERA5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Go to the ERA5 hourly data on single levels from 1979 to present (https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form)\n",
    "\n",
    "b) In product type select Reanalysis\n",
    "\n",
    "c) In Variable select Popular -> 10m u-component of wind, 10m v-component of wind, and Mean sea level pressure.\n",
    "\n",
    "d) In this example we will prepare the data for Hurricane Arthur, from 06/27/2014 to 07/09/2014. Therefore, we will have to download 2 ERA5 files, one from 06/27/2014 to 06/30/2014 and another from 07/01/2014 to 07/09/2014. \n",
    "\n",
    "First, we will download the data from 06/27/2014 to 06/30/2014. To do that we just need to select the Year, Month and Day accordingly. We will work with inputs every 6 hours, so select the Time: 00:00, 06:00, 12:00, and 18:00.\n",
    "\n",
    "e) In the Geographical area tab select “Whole available region”\n",
    "\n",
    "f) Select the GRIB format in the Format tab.\n",
    "\n",
    "g) Click on “Show API request” and save the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Downloading ERA5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary lybraries:\n",
    "\n",
    "\n",
    "cfgrib is installed as:\n",
    "conda install -c conda-forge cfgrib\n",
    "xarray is installed as:\n",
    "conda install -c conda-forge xarray dask netCDF4 bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,getopt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import numpy.core.multiarray \n",
    "import netCDF4 as nc4\n",
    "import xarray as xr\n",
    "import scipy.interpolate\n",
    "import cdsapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste the API request and start downloading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-09 14:14:09,064 INFO Welcome to the CDS\n",
      "2020-04-09 14:14:09,068 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2020-04-09 14:14:10,938 INFO Request is completed\n",
      "2020-04-09 14:14:10,941 INFO Downloading http://136.156.132.198/cache-compute-0003/cache/data3/adaptor.mars.internal-1586349034.2352884-14786-33-c4c25e88-3359-4a03-93f2-1341c4d937ff.grib to download.grib (95.1M)\n",
      "2020-04-09 14:14:20,799 INFO Download rate 9.6M/s                                                                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(content_length=99676800,content_type=application/x-grib,location=http://136.156.132.198/cache-compute-0003/cache/data3/adaptor.mars.internal-1586349034.2352884-14786-33-c4c25e88-3359-4a03-93f2-1341c4d937ff.grib)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = cdsapi.Client()\n",
    "\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels',\n",
    "    {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'grib',\n",
    "        'variable': [\n",
    "            '10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure',\n",
    "        ],\n",
    "        'year': '2014',\n",
    "        'month': '06',\n",
    "        'day': [\n",
    "            '27', '28', '29',\n",
    "            '30',\n",
    "        ],\n",
    "        'time': [\n",
    "            '00:00', '06:00', '12:00',\n",
    "            '18:00',\n",
    "        ],\n",
    "    },\n",
    "    'download.grib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Converting the .grib file into .22 (NWS=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to where the .grib data was saved:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the .grib file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pl.Path(r'C:\\Users\\fcassalh')\n",
    "file = 'download.grib'\n",
    "grib = xr.open_dataset(path / file, engine='cfgrib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the variables of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = grib.data_vars['u10'].values[:]\n",
    "v = grib.data_vars['v10'].values[:]\n",
    "prmsl = grib.data_vars['msl'].values[:]\n",
    "lat = grib.coords['latitude'].values\n",
    "lon= grib.coords['longitude'].values\n",
    "time = grib.coords['time'].values[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create boundaries that cover the extent of your mesh (in our case the North Atlantic and the Caribean):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1,lat2 = 7,60\n",
    "lon1,lon2 = -100, -58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a grid in using the format expected for a NWS = 6 in 3 columns (uwind, vwind, pressure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp,y,x = u.shape\n",
    "u2,v2,p2 = [],[],[]\n",
    "datay,datax = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start populating the grid with data from the .grib file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in time:\n",
    "    for i in range(0,y):\n",
    "        for ii in range(0,x):\n",
    "            if (lat2>=lat[i]>lat1) and ((lon2+360)>=lon[ii]>(lon1+360)):\n",
    "                u2.append(np.round(u[t,i,ii],3))\n",
    "                v2.append(np.round(v[t,i,ii],3))\n",
    "                p2.append(prmsl[t,i,ii])\n",
    "                datay.append(i)\n",
    "                datax.append(ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the grid in the correct format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'u':np.round(u2,2),'v':np.round(v2,2),'p':np.round(p2,2)})\n",
    "df.to_csv('Arthur_part1.22', sep='\\t',index=False,header = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat steps 1, 2, and 3 for the second part of the storm\n",
    "\n",
    "Make sure that when you repeat the process for the other part of the storm (07/01/2014 to 07/09/2014) you change the name of the output file.\n",
    "\n",
    "Use a text editor (Sublime for instance) to copy the 'arthur_2.22' file at the end of the 'arthur_1.22' file. This complete file refers to the whole storm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the extent of your grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 168)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = lat[(lat2>=lat) & (lat>lat1)]\n",
    "temp2 = lon[(lon2+360>=lon) & (lon>lon1+360)]\n",
    "len(temp),len(temp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the fort.15 file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the line YYYY MM DD HH24 to:\n",
    "\n",
    "212 168 60.0 -100.0 0.25 0.25 21600 3600 ! YYYY MM DD HH24 StormNumber BLAdj \n",
    "\n",
    "where, 212 is the number of values in Y, 168 is the number of values in X, 60 is the maximum Y, -100 is the minimum X, 0.25 are the X and Y increments, and 21600 is the time interval in seconds (6hours)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
