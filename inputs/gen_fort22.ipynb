{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#from osgeo import gdal # Import the GDAL library\n",
    "import sys,getopt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import numpy.core.multiarray \n",
    "import netCDF4 as nc4\n",
    "import xarray as xr\n",
    "import scipy.interpolate\n",
    "import requests\n",
    "import cdsapi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Keys for GFS grib reanalsis:\n",
    "u-component_of_wind_height_above_ground\n",
    "v-component_of_wind_height_above_ground\n",
    "Pressure_surface\n",
    "160 -> 240\n",
    "87 -> 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-06 18:58:03,066 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2020-04-06 18:58:03,717 INFO Request is queued\n",
      "2020-04-06 18:58:04,815 INFO Request is running\n",
      "2020-04-06 18:58:25,077 INFO Request is completed\n",
      "2020-04-06 18:58:25,078 INFO Downloading http://136.156.132.236/cache-compute-0007/cache/data5/adaptor.mars.internal-1586213885.097692-5149-39-4489739b-4d95-4986-bfce-921a9ed92091.grib to joaquin2.grib (712.9M)\n",
      "2020-04-06 18:59:58,566 INFO Download rate 7.6M/s                                                                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(content_length=747576000,content_type=application/x-grib,location=http://136.156.132.236/cache-compute-0007/cache/data5/adaptor.mars.internal-1586213885.097692-5149-39-4489739b-4d95-4986-bfce-921a9ed92091.grib)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = cdsapi.Client()\n",
    "time = ['00:00', '01:00', '02:00','03:00', '04:00', '05:00',\n",
    "        '06:00', '07:00', '08:00','09:00', '10:00', '11:00',\n",
    "        '12:00', '13:00', '14:00','15:00', '16:00', '17:00',\n",
    "        '18:00', '19:00', '20:00','21:00', '22:00', '23:00',]\n",
    "days = ['01','02','03','04','05'\n",
    "        ]        #,'03','04','05','06','07','08','09','10','11','12','13','14''18','19','20','21','22','23','24','25','26','27','28','29','30'\n",
    "        \n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels',\n",
    "    {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'grib',\n",
    "        'variable': [\n",
    "            '10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure',\n",
    "        ],\n",
    "        'year': '2015',\n",
    "        'month': '10',\n",
    "        'day': days,\n",
    "\n",
    "        'time': time,\n",
    "    },\n",
    "    'joaquin2.grib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-06 19:00:00,025 INFO missing from GRIB stream: 'directionNumber'\n",
      "2020-04-06 19:00:00,026 INFO missing from GRIB stream: 'frequencyNumber'\n",
      "2020-04-06 19:00:00,414 INFO missing from GRIB stream: 'directionNumber'\n",
      "2020-04-06 19:00:00,415 INFO missing from GRIB stream: 'frequencyNumber'\n",
      "2020-04-06 19:00:00,720 INFO missing from GRIB stream: 'directionNumber'\n",
      "2020-04-06 19:00:00,720 INFO missing from GRIB stream: 'frequencyNumber'\n"
     ]
    }
   ],
   "source": [
    "path = pl.Path(r'D:\\FHRL_work\\libraries\\adcirc-unswan\\inputs')\n",
    "file = 'joaquin2.grib'\n",
    "grib = xr.open_dataset(path  / file, engine='cfgrib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pl.Path(r'D:\\temp')\n",
    "file = 'wnd10m.gdas.201610.grib2'\n",
    "grib = xr.open_dataset(path  / file, engine='cfgrib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:            (latitude: 880, longitude: 1760, step: 7, time: 124)\n",
       "Coordinates:\n",
       "  * time               (time) datetime64[ns] 2016-10-01 ... 2016-10-31T18:00:00\n",
       "  * step               (step) timedelta64[ns] 00:00:00 01:00:00 ... 06:00:00\n",
       "    heightAboveGround  int32 ...\n",
       "  * latitude           (latitude) float64 89.84 89.64 89.44 ... -89.64 -89.84\n",
       "  * longitude          (longitude) float64 0.0 0.2045 0.4091 ... 359.6 359.8\n",
       "    valid_time         (time, step) datetime64[ns] ...\n",
       "Data variables:\n",
       "    u10                (time, step, latitude, longitude) float32 ...\n",
       "    v10                (time, step, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    GRIB_edition:            2\n",
       "    GRIB_centre:             kwbc\n",
       "    GRIB_centreDescription:  US National Weather Service - NCEP \n",
       "    GRIB_subCentre:          0\n",
       "    Conventions:             CF-1.7\n",
       "    institution:             US National Weather Service - NCEP \n",
       "    history:                 2020-04-09T13:19:36 GRIB to CDM+CF via cfgrib-0....</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:            (latitude: 880, longitude: 1760, step: 7, time: 124)\n",
       "Coordinates:\n",
       "  * time               (time) datetime64[ns] 2016-10-01 ... 2016-10-31T18:00:00\n",
       "  * step               (step) timedelta64[ns] 00:00:00 01:00:00 ... 06:00:00\n",
       "    heightAboveGround  int32 ...\n",
       "  * latitude           (latitude) float64 89.84 89.64 89.44 ... -89.64 -89.84\n",
       "  * longitude          (longitude) float64 0.0 0.2045 0.4091 ... 359.6 359.8\n",
       "    valid_time         (time, step) datetime64[ns] ...\n",
       "Data variables:\n",
       "    u10                (time, step, latitude, longitude) float32 ...\n",
       "    v10                (time, step, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    GRIB_edition:            2\n",
       "    GRIB_centre:             kwbc\n",
       "    GRIB_centreDescription:  US National Weather Service - NCEP \n",
       "    GRIB_subCentre:          0\n",
       "    Conventions:             CF-1.7\n",
       "    institution:             US National Weather Service - NCEP \n",
       "    history:                 2020-04-09T13:19:36 GRIB to CDM+CF via cfgrib-0...."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u = grib.data_vars['u10'].values[:,:,:,:]\n",
    "#v = grib.data_vars['v10'].values[:,:,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = grib.coords['time'].values[:]\n",
    "step = grib.coords['step'].values[:]\n",
    "lat = grib.coords['latitude'].values\n",
    "lon = grib.coords['longitude'].values\n",
    "\n",
    "# if you want to split the time\n",
    "start = '2016-10-05 00:00:00'\n",
    "end = '2016-10-20 00:00:00'\n",
    "start_split = np.where(((pd.to_datetime(start)-pd.Timedelta(hours=1))<pd.to_datetime(time))&(pd.to_datetime(time)<=(pd.to_datetime(start)+pd.Timedelta(hours=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16], dtype=int64),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot include dtype 'M' in a buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c43671cd095e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot include dtype 'M' in a buffer"
     ]
    }
   ],
   "source": [
    "time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For CFSv2 monthly reanylisis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1362354 1362354 1362354\n",
      "2724708 2724708 2724708\n",
      "4087062 4087062 4087062\n",
      "5449416 5449416 5449416\n",
      "6811770 6811770 6811770\n",
      "8174124 8174124 8174124\n",
      "9536478 9536478 9536478\n",
      "10898832 10898832 10898832\n",
      "12261186 12261186 12261186\n",
      "13623540 13623540 13623540\n",
      "14985894 14985894 14985894\n",
      "16348248 16348248 16348248\n",
      "17710602 17710602 17710602\n",
      "19072956 19072956 19072956\n",
      "20435310 20435310 20435310\n",
      "21797664 21797664 21797664\n",
      "23160018 23160018 23160018\n",
      "24522372 24522372 24522372\n",
      "25884726 25884726 25884726\n",
      "27247080 27247080 27247080\n"
     ]
    }
   ],
   "source": [
    "path = pl.Path(r'D:\\temp')\n",
    "file = 'prmsl.gdas.201610.grib2'\n",
    "grib = xr.open_dataset(path / file , engine='cfgrib')\n",
    "prmsl = grib.variables['prmsl'].values[:,:,:,:]\n",
    "\n",
    "lat1,lat2 = -80,20\n",
    "lon1,lon2 = -82, -0.5\n",
    "\n",
    "# ---- generate adcirc forcing file (fort.22)---------\n",
    "\n",
    "t1,t2,y,x = u.shape\n",
    "u2,v2,p2 = [],[],[]\n",
    "datay,datax = [], []\n",
    "for t in range(t1):\n",
    "    for tt in range(0,t2,1):\n",
    "        for i in range(0,y):\n",
    "            for ii in range(0,x):\n",
    "                if lat2>=lat[i]>lat1 and (lon1+360)<=lon[ii]<(lon2+360):\n",
    "                    datay.append(i)\n",
    "                    datax.append(ii)\n",
    "                    u2.append(np.round(u[t,tt,i,ii],3))\n",
    "                    v2.append(np.round(v[t,tt,i,ii],3))\n",
    "                    y2 = int(np.floor(i*0.409))\n",
    "                    x2 = int(np.floor(ii*0.409))\n",
    "                    p2.append(prmsl[t,tt,y2,x2])\n",
    "    print(len(u2),len(v2),len(p2))\n",
    "df = pd.DataFrame({'u':np.round(u2,2),'v':np.round(v2,2),'p':np.round(p2,2)})\n",
    "df.to_csv('fort.22', sep='\\t',index=False,header = False)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489, 398)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = lat[(lat2>=lat) & (lat>lat1)]\n",
    "temp2 = lon[(lon2+360>=lon) & (lon>lon1+360)]\n",
    "len(temp),len(temp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For ERA 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1,lat2 = -80,20\n",
    "lon1,lon2 = -82, -0.5\n",
    "\n",
    "lat = grib.coords['latitude'].values\n",
    "lon= grib.coords['longitude'].values\n",
    "time = np.arange(0,len(grib.coords['time'][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1,lat2 = 7,60\n",
    "lon1,lon2 = -100, -58\n",
    "\n",
    "lat = grib.coords['latitude'].values\n",
    "lon= grib.coords['longitude'].values\n",
    "time = np.arange(0,len(grib.coords['time'][:]))\n",
    "\n",
    "\n",
    "temp,y,x = u.shape\n",
    "u2,v2,p2 = [],[],[]\n",
    "datay,datax = [], []\n",
    "for t in time:\n",
    "    for i in range(0,y):\n",
    "        for ii in range(0,x):\n",
    "            if (lat2>=lat[i]>lat1) and ((lon2+360)>=lon[ii]>(lon1+360)):\n",
    "                u2.append(np.round(u[t,i,ii],3))\n",
    "                v2.append(np.round(v[t,i,ii],3))\n",
    "                p2.append(prmsl[t,i,ii])\n",
    "                datay.append(i)\n",
    "                datax.append(ii)\n",
    "\n",
    "df = pd.DataFrame({'u':np.round(u2,2),'v':np.round(v2,2),'p':np.round(p2,2)})\n",
    "df.to_csv('joaquin2.22', sep='\\t',index=False,header = False)  \n",
    "\n",
    "temp = lat[(lat2>=lat) & (lat>lat1)]\n",
    "temp2 = lon[(lon2+360>=lon) & (lon>lon1+360)]\n",
    "len(temp),len(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potentially GFS and GEFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gfsanl_3_20080701_0000_000.grb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n            for key in dataset.keys():\\n                temp = test.GetRasterBand(dataset[key])\\n                data[key] = temp.ReadAsArray()\\n\\n            for i in range(0,90):\\n                for ii in range(160,245):\\n                    u_wind.append(round(data['u_wind'][i,ii],3))\\n                    v_wind.append(round(data['v_wind'][i,ii],3))\\n                    psl.append(round(data['psl'][i,ii],3))\\n        if t==20 and m==8:\\n            break\\n    \\ndf = pd.DataFrame({'u':u_wind,'v':v_wind,'p':psl})\\ndf.to_csv('fort.22', sep='\\t',index=False,header = False)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'ftp://nomads.ncdc.noaa.gov/GFS/analysis_only/200807/20080701/'\n",
    "\n",
    "day = 1\n",
    "data = {}\n",
    "u_wind,v_wind,psl = [],[],[]\n",
    "name = []\n",
    "for m in range(7,8):\n",
    "    for t in range(1,2):\n",
    "        if t < 10:\n",
    "            t_s = '0'+str(t)\n",
    "        else:\n",
    "            t_s = str(t)\n",
    "        url =  'ftp://nomads.ncdc.noaa.gov/GFS/analysis_only/20080{}/20080{}{}/'.format(str(m),str(m),t_s)\n",
    "\n",
    "        for hour in range(0,1):\n",
    "            if hour==0 or hour==6:\n",
    "                time = '0'+str(hour)\n",
    "            else:\n",
    "                time = str(hour)\n",
    "            \n",
    "            file = 'gfsanl_3_20080{}{}_{}00_000.grb'.format(m,t_s,time)\n",
    "            print(file)\n",
    "            name.append(file)\n",
    "            test = gdal.Open(url+file)\n",
    "'''\n",
    "            for key in dataset.keys():\n",
    "                temp = test.GetRasterBand(dataset[key])\n",
    "                data[key] = temp.ReadAsArray()\n",
    "\n",
    "            for i in range(0,90):\n",
    "                for ii in range(160,245):\n",
    "                    u_wind.append(round(data['u_wind'][i,ii],3))\n",
    "                    v_wind.append(round(data['v_wind'][i,ii],3))\n",
    "                    psl.append(round(data['psl'][i,ii],3))\n",
    "        if t==20 and m==8:\n",
    "            break\n",
    "    \n",
    "df = pd.DataFrame({'u':u_wind,'v':v_wind,'p':psl})\n",
    "df.to_csv('fort.22', sep='\\t',index=False,header = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
